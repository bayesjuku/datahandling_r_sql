[["index.html", "データハンドリング実践入門 - RとSQLの比較 はじめに 参考資料", " データハンドリング実践入門 - RとSQLの比較 前田和寛(@kazutan) 2021-09-12 はじめに 本編は次のページ以降になります 参考資料 WIP… "],["00_intro.html", "1 データハンドリング実践入門 - RとSQLの比較 1.1 目的 1.2 構成 1.3 制約", " 1 データハンドリング実践入門 - RとSQLの比較 1.1 目的 分析業務の現場で行うデータハンドリング事例を紹介 同一の加工をRとSQLで実践する SQL入門も兼ねて 1.2 構成 (WIP) 1.3 制約 ここでは基本的にテーブル構造のデータを中心に説明していきます。 list/arrayタイプのようなデータ構造はここでは詳細に触れません。 ご了承ください。 "],["01_r_and_sql_setting.html", "2 データハンドリングの考え方/環境準備 2.1 構成 2.2 データハンドリングの考え方 2.3 Rによるデータハンドリング 2.4 SQLによるデータハンドリング 2.5 参考資料", " 2 データハンドリングの考え方/環境準備 2.1 構成 データハンドリングの考え方 基本的な流れ Rによるデータハンドリング イメージ 環境準備 SQLによるデータハンドリング イメージ 環境準備 2.2 データハンドリングの考え方 ぶっちゃけ、料理と一緒ですね。 2.2.1 基本的な流れ データハンドリングは、基本的に以下の流れを1つのunitとして考えます: データオブジェクトを準備 削除 カラム(列)の選択/削除(横を変える) レコード(行)の選択/削除(縦を変える) 加工/追加 カラム内の値/型の変換 1 カラムを追加 集約 集約化変数の指定 集約による行圧縮 結合 結合対象のデータオブジェクトを準備 結合方向の指定 データオブジェクト間の結合 データオブジェクトの出力 そして、あとはこれをつなげていって全体を達成します1。｢えっ、group_byして集約した後に加工したりするじゃん?｣と思うかもしれません。しかしそれは、以下のように考えることができます: unit 1 df_A を準備 (削りなしなのでスキップ) (加工なしなのでスキップ) 集約 group_by して集計値を出す (結合なしなのでスキップ) df_A_01 を出力 unit 2 df_A_01を準備 (削りなしなのでスキップ) 加工 sumがmeanを超えたら1とする etc… (集約なしなのでスキップ) (結合なしなのでスキップ) df_A_02を出力 これでスキップをなくすと、以下のようになります: unit 1 df_A を準備 集約 group_by して集計値を出す df_A_01 を出力 unit 2 df_A_01を準備 加工 sumがmeanを超えたら1とする etc… df_A_02を出力 さらに、unit_1の出力とunit_2の準備(入力)は繋がっているので、こういう書き方(太字)もできます: unit 1 df_A を準備 集約 group_by して集計値を出す df_A_01 を出力 unit 2 unit 1の出力df_A_01を準備 加工 sumがmeanを超えたら1とする etc… df_A_02を出力 これにより、2つのunitが繋がった書き方となります。これで依存関係なども表現できるようになりましたね。 データハンドリングは、 最終的に欲しい形のデータを決める 最終形態に必要なデータを準備 unitおよびフローを｢計画｣する 計画したunit flowを実行できるよう｢記述｣する 記述した計画を実行する …となります。データハンドリングをする際は、必ずこれを意識してください。 2.3 Rによるデータハンドリング 今なら宇宙船本がありますよ! https://gihyo.jp/book/2021/978-4-297-12170-9 2.3.1 イメージ 今回はtidyverseの世界で説明します。 data.frameおよびtibbleは、ともに列志向のデータオブジェクトです。｢列志向｣とは｢データの区切りとしてまず列がある｣というものです。｢dfは7つのcolumnがある｣-&gt;｢1つの列は100のデータを持つ｣…という階層構造になっていることを指します2。従って、列を意識する必要があります。 Rでもデータハンドリングの考え方は上述のとおりで、tidyverseはunitの各機能に対応するfunctionを提供しています。また、パイプ演算子はunit間を繋いでいく役目をしていますので、こんな感じの表現もできますね: unit 1 &amp; unit 2 df_A を準備 集約 group_by して集計値を出す (出力が生成されるけどpipeされる) %&gt;% ( %&gt;% で送られてきたものを受け取る) 加工 sumがmeanを超えたら1とする etc… df_A_02を出力 あとはこれをRのスクリプトで｢記述｣すればOKですね。 2.3.2 環境準備 今回はtidyverseの世界で説明します。 R/RStudioをインストール tidyverseを入れる 2.4 SQLによるデータハンドリング 2.4.1 SQL/RDBの基礎 このスライド以上の説明がないのでこれみてください: この内容をある程度網羅的に実践して、いくつか実際に書いてみればだいたい書けるようになります。なので基礎部分は省略。 2.4.2 イメージ SQLは、｢データを加工するプロセスを記述するための言語｣です。なので、上述したunitのプロセスを書き起こしたものとなります。Rではわりとフローを意識したコーディングになるのですが、SQLではunitを非常に意識したコーディングとなります。 …というか、このunitという観点については、私はSQLでデータハンドリングしててそう考えるようになりました。なので、上述のunitのイメージができるようになれば、あとは辞書的なものを参照しながら書けるようになります。 2.4.3 環境準備 今回はRDBとしてSQLiteを利用します。SQLiteは以下の特徴があります: ファイルをDB dataとして扱える 軽量で手元で簡単にできる そこまで大きくないデータであれば十分に使える 独自関数はあんまりない(逆に入門として扱いやすい) でもwindow関数は使える https://www.sqlite.org/windowfunctions.html もちろんR/RStudioから利用可能 (ほかは口頭で) 2.4.3.1 SQLiteの準備 Windowsの場合 適当にググってください Macの場合 デフォルトでインストールされています Ubuntuの場合 sudo apt install sqlite でOK Terminalを起動して、sqlite3を実行して出てきてくれればOK。終了コマンドは .quitです。ヘルプは.helpで表示されます。 2.5 参考資料 (WIP) ピボット変換(wideとlongの変換)がここには入っていません。これはSQLでのピボット変換コードを見るとわかるのですが、実は｢削除｣｢加工｣｢集約｣｢結合｣を組み合わせて表現できます。また並べ替えについても同様です。↩︎ よく誤解されますが、Rにおいて行列は｢ベクトル｣です。一見data.frameっぽく見えますが、あれはベクトルに指定した次元情報をもたせただけの｢1つのベクトル｣です。なので全ての値で同一のデータ型しか許可しません。列志向も行志向もないです。↩︎ "],["02_prepare_exec_env.html", "3 実行環境の準備 3.1 libraryの準備 3.2 RSQLite チュートリアル 3.3 今回のデータの準備", " 3 実行環境の準備 3.1 libraryの準備 個人的にRStudio上で全て作業したいので、それを前提とします。 3.1.1 R/RStudio, SQLiteのインストール -&gt; 前節参照 3.1.2 RStudioからSQLiteを扱えるようにする RSQLiteパッケージ RからSQLiteへアクセスするためのドライバなどを提供するパッケージ 開発陣が大物ばかり DBIパッケージ RからDBへ接続する関数を提供するパッケージ RSQLiteパッケージをインストールすれば多分入るはず 3.2 RSQLite チュートリアル これを読もう https://rsqlite.r-dbi.org/articles/rsqlite これを簡単に試しましょう 3.2.1 接続テスト …その前に、｢開いたconは閉じる｣を頭に入れておいてください。 # library library(DBI) library(tidyverse) library(lubridate) # connect DB # 指定したファイルパスへsqliteで接続(connect) # 指定したパスにファイルがない場合、下のファイル名で作成される mydb &lt;- dbConnect(RSQLite::SQLite(), &quot;my-db.sqlite&quot;) # 接続を切断 dbDisconnect(mydb) # 接続先を削除 # SQLiteで上記のようにディスク上のファイルを指定した場合、｢そのファイルが削除｣される unlink(&quot;my-db.sqlite&quot;) # mydbは｢接続情報｣オブジェクト # なので、これを使って再度connectできる # さっきunlinkしたけど、これでまた復帰します mydb &lt;- dbConnect(mydb) # dbConnectを書いたらすぐにdbDisconnectを書きましょう dbDisconnect(mydb) 3.2.2 tableを作る とりあえず、Rのいくつかのdata.frameをDB内のtableに書き出してみましょう # write table and check----- # dbへconnect mydb_writetbl &lt;- dbConnect(RSQLite::SQLite(), # DB接続のドライバを指定 &quot;my-db.sqlite&quot;) # 接続先を指定(今回のSQLiteはファイルパス) # write table - iris dbWriteTable(mydb_writetbl, # dbConnectオブジェクト、すなわち接続するDB &quot;t_iris&quot;, # table名 iris, # 書き込むデータ。ここではiris overwrite = TRUE) # 上書きするか。実際には細心の注意を # write table - mtcars dbWriteTable(mydb_writetbl, &quot;t_mtcars&quot;, mtcars, overwrite = TRUE) # 細心の注意を # 閉じる dbDisconnect(mydb_writetbl) # 開いたconは閉じろ これで、2つのtableに書き出せたので、実際に入っているか確認しましょう # もう一回DBにつなぐ # connectionオブジェクトだけを指定してもOK con &lt;- dbConnect(mydb) # DB内の全てのtableをリストアップ dbListTables(con) ## [1] &quot;t_iris&quot; &quot;t_mtcars&quot; これで2つのテーブルが書けたので、簡単にテストをしていきましょう。 3.2.3 tableへの問い合わせ(query) queryとは｢問い合わせる｣という意味です。なのでここでは｢DBにぶん投げる問い合わせ内容｣となります。 # irisを5行もってくる dbGetQuery(con, #接続先 &#39;select * from t_iris limit 5&#39;) # SQL query ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa もちろんsqlの結果をR側のオブジェクトとして受けることもできます iris_from_db &lt;- dbGetQuery(con, &#39;select * from t_mtcars&#39;) head(iris_from_db, 3) 現在、パラメータ化も使えるようになってます # 詳細はチュートリアルを参照 dbGetQuery(con, &#39;SELECT * FROM t_iris WHERE &quot;Sepal.Length&quot; &lt; :x&#39;, params = list(x = 4.6)) # 開いたconは閉じろ dbDisconnect(con) 3.3 今回のデータの準備 今回は、以下のsiteの仮想データを利用します: ログデータ処理で始めるlubridate入門 ここの2に、仮想ログデータを作成するRコードがあります ただ、今回はDB的なデータ構造にしたいので、DBの正規化をしてitem masterを分離させます。正規化については適当にググってください。 3.3.1 R側の仮想データ作成 上記のサイトのコードをベースに作成します: # params setting start &lt;- &quot;2018-1-1 00:00:00&quot; #開始日 n &lt;- 10000 # 購入件数 duration_days &lt;- 50 # ログの期間(日数) list_price &lt;- c(100, 500, 1000, 2000, 5000) # アイテムの価格リスト list_item &lt;- paste(&quot;item&quot;, 1:length(list_price), sep = &quot;_&quot;) # アイテムリスト list_item_p &lt;- c(100, 50, 10, 5, 2) # 発生比 list_id &lt;- 1000001:1000300 # 会員id # ログデータ生成 df_log &lt;- data.frame( # タイムスタンプを作成 # 開始日時を生成 stamp = ymd_hms(start) + # 0-50までの整数からランダムに10000件生成し、それを日数データに変換して足す days(sample(0:duration_days, n, replace = TRUE)) + # 0-23までの整数からランダムに10000件生成し、それを時間データに変換して足す hours(sample(0:23, n, replace = TRUE)) + # 0-59までの整数からランダムに10000件生成し、それを分データに変換して足す minutes(sample(0:59, n, replace = TRUE)) + # 0-59までの整数からランダムに10000件生成し、それを病データに変換して足す seconds(sample(0:59, n, replace = TRUE)), # 会員IDをランダムに生成 id = sample(list_id, n, replace = TRUE), # アイテム名をランダムに生成 item = sample(list_item, n, replace = TRUE, prob = list_item_p) ) %&gt;% # ログデータっぽく、タイムスタンプで並べ替える arrange(stamp) # 生成できているかを確認 knitr::kable(sample_n(df_log, 10)) あわせて、itemのmaster tableを作成します # itemのmaster dfを作成 df_item_master &lt;- tibble( item = list_item, value = list_price ) # 生成できているかを確認 knitr::kable(df_item_master) 3.3.2 DB側の準備 作成したRのオブジェクトをtableに書き出します # conを開く con &lt;- dbConnect(con) # tbl書き込み dbWriteTable(con, &quot;t_df_log&quot;, df_log, overwrite = TRUE) #今日は何度も書くので dbWriteTable(con, &quot;t_df_item_master&quot;, df_item_master, overwrite = TRUE) #今日は何度も書くので # 生成できているかをチェック dbGetQuery(con, &#39;select * from t_df_log limit 5&#39;) dbGetQuery(con, &#39;select * from t_df_item_master&#39;) これでDBに作成できたので、実際にRを比較していきましょう。開いたconは閉じましょう。 # 開いたconは閉じろ dbDisconnect(con) "],["03_logdata_handling_r_and_sql.html", "4 ログデータハンドリング - RとSQLでの比較 4.1 データの準備 4.2 Q1 日別の売上集計", " 4 ログデータハンドリング - RとSQLでの比較 4.1 データの準備 前節で作成したデータはDBにあります。てことでR側はそこから取得しましょう。 # library library(DBI) library(tidyverse) library(lubridate) # db con # 事前に前節でデータを作成している前提です con &lt;-dbConnect(RSQLite::SQLite(), &quot;my-db.sqlite&quot;) # read tableして格納 df_log &lt;- dbReadTable(con, &quot;t_df_log&quot;) df_item_master &lt;- dbReadTable(con, &quot;t_df_item_master&quot;) SQLは直接queryを投げるので、ここでは特に必要ありません。 4.2 Q1 日別の売上集計 日別の売上合計を算出しましょう 4.2.1 Rによるデータハンドリング df_res_01_r &lt;- df_log %&gt;% left_join(df_item_master) %&gt;% # item masterの情報でvalueを持ってくる mutate(date_time = as_datetime(stamp, tz = &#39;Asia/Tokyo&#39;), # なぜかunixtimeになってた… date = date(date_time)) %&gt;% # timestampからdateに変換 group_by(date) %&gt;% # 日付でgroup_by summarise( n = n(), total = sum(value) ) # チェック head(df_res_01_r, 5) unitに分けて考えます unit_1: logに価格を追加 入力: df_logを準備 (削除はスキップ) (加工はスキップ) (集約はスキップ) 結合: df_item_masterを準備 left join keyになる変数は両方とも item 出力: %&gt;% unit_2へ unit_2 日付のカラムを作成 入力: unit_1からpipe (削除はスキップ) 加工 stampがunixtimeなのでdate-time型 date_timeへ date-time型 date_time から date型 date へ (集約はスキップ) (結合はスキップ) 出力: %&gt;% unit_3へ unit_3: 集約して集計 入力: unit_2からpipe 削除: date以外を除外 加工 count -&gt; nへ sum -&gt; totalへ 集約: dateでgroup_by (結合はスキップ) 出力: df_res_01_rとして出力 このような感じになります。 4.2.2 SQLによるデータハンドリング では、SQLによって同じ操作を行います # sql_queryを作成 query_01 &lt;- &quot; select date ,count(*) as n ,sum(value) as total from ( select unit_1.* ,date(datetime(stamp, &#39;unixepoch&#39;, &#39;localtime&#39;)) as date --後述 from ( select log.* ,im.value from t_df_log as log left join t_df_item_master as im on log.item = im.item ) as unit_1 ) as unit_2 group by 1 order by 1 &quot; df_res_01_sql &lt;- dbGetQuery(con, query_01) head(df_res_01_sql, 5) 同一の結果が得られました。 さて、上記のSQLコードはRで書いたunitでの考え方に合わせてます。(続く…) # 開いたconは閉じろ dbDisconnect(con) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
