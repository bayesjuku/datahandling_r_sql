---
output: html_document
---

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = FALSE)
```

# データハンドリングの考え方/環境準備


## 構成

- データハンドリングの考え方
  - 基本的な流れ
- Rによるデータハンドリング
  - イメージ
  - 環境準備
- SQLによるデータハンドリング
  - イメージ
  - 環境準備


## データハンドリングの考え方

ぶっちゃけ、料理と一緒ですね。

### 基本的な流れ

データハンドリングは、基本的に以下の流れを1つのunitとして考えます:

1. データオブジェクトを準備
1. 削除
    1. カラム(列)の選択/削除(横を変える)
    1. レコード(行)の選択/削除(縦を変える)
1. 加工/追加
    1. カラム内の値/型の変換
    1  カラムを追加
1. 集約
    1. 集約化変数の指定
    1. 集約による行圧縮
1. 結合
    1. 結合対象のデータオブジェクトを準備
    1. 結合方向の指定
    1. データオブジェクト間の結合
1. データオブジェクトの出力

そして、あとはこれをつなげていって全体を達成します[^wide_long]。｢えっ、`group_by`して集約した後に加工したりするじゃん?｣と思うかもしれません。しかしそれは、以下のように考えることができます:

1. unit 1
    1. `df_A` を準備
    1. (削りなしなのでスキップ)
    1. (加工なしなのでスキップ)
    1. 集約
        1. `group_by` して集計値を出す
    1. (結合なしなのでスキップ)
    1. `df_A_01` を出力
1. unit 2
    1. `df_A_01`を準備
    1. (削りなしなのでスキップ)
    1. 加工
        1. `sum`が`mean`を超えたら`1`とする etc...
    1. (集約なしなのでスキップ)
    1. (結合なしなのでスキップ)
    1. `df_A_02`を出力

これでスキップをなくすと、以下のようになります:

1. unit 1
    1. `df_A` を準備
    1. 集約
        1. `group_by` して集計値を出す
    1. `df_A_01` を出力
1. unit 2
    1. `df_A_01`を準備
    1. 加工
        1. `sum`が`mean`を超えたら`1`とする etc...
    1. `df_A_02`を出力

さらに、unit_1の出力とunit_2の準備(入力)は繋がっているので、こういう書き方(太字)もできます:

1. unit 1
    1. `df_A` を準備
    1. 集約
        1. `group_by` して集計値を出す
    1. `df_A_01` を出力
1. unit 2
    1. **unit 1の出力`df_A_01`を準備**
    1. 加工
        1. `sum`が`mean`を超えたら`1`とする etc...
    1. `df_A_02`を出力

これにより、2つのunitが繋がった書き方となります。これで依存関係なども表現できるようになりましたね。

データハンドリングは、

- 最終的に欲しい形のデータを決める
- 最終形態に必要なデータを準備
- unitおよびフローを｢計画｣する
- 計画したunit flowを実行できるよう｢記述｣する
- 記述した計画を実行する

...となります。データハンドリングをする際は、必ずこれを意識してください。


## Rによるデータハンドリング

今なら宇宙船本がありますよ! <https://gihyo.jp/book/2021/978-4-297-12170-9>

### イメージ

今回はtidyverseの世界で説明します。

`data.frame`および`tibble`は、ともに列志向のデータオブジェクトです。｢列志向｣とは｢データの区切りとしてまず列がある｣というものです。｢dfは7つのcolumnがある｣->｢1つの列は100のデータを持つ｣...という階層構造になっていることを指します[^matrix]。従って、列を意識する必要があります。

Rでもデータハンドリングの考え方は上述のとおりで、tidyverseはunitの各機能に対応するfunctionを提供しています。また、パイプ演算子はunit間を繋いでいく役目をしていますので、こんな感じの表現もできますね:

1. unit 1 & unit 2
    1. `df_A` を準備
    1. 集約
        1. `group_by` して集計値を出す
    1. (出力が生成されるけどpipeされる)
1. `%>%`
    1. ( %>% で送られてきたものを受け取る)
    1. 加工
        1. `sum`が`mean`を超えたら`1`とする etc...
    1. `df_A_02`を出力

あとはこれをRのスクリプトで｢記述｣すればOKですね。


### 環境準備

今回はtidyverseの世界で説明します。

- R/RStudioをインストール
- tidyverseを入れる


## SQLによるデータハンドリング

### SQL/RDBの基礎

このスライド以上の説明がないのでこれみてください:

```{r embed_slide1, eval=TRUE, echo=FALSE}
# zousan package are here: https://github.com/kazutan/zousan

zousan::embed_slide("https://speakerdeck.com/brainpadpr/sql-for-data-handling")
```

この内容をある程度網羅的に実践して、いくつか実際に書いてみればだいたい書けるようになります。なので基礎部分は省略。


### イメージ

SQLは、｢データを加工するプロセスを記述するための言語｣です。なので、上述したunitのプロセスを書き起こしたものとなります。Rではわりとフローを意識したコーディングになるのですが、SQLではunitを非常に意識したコーディングとなります。

...というか、このunitという観点については、私はSQLでデータハンドリングしててそう考えるようになりました。なので、上述のunitのイメージができるようになれば、あとは辞書的なものを参照しながら書けるようになります。

### 環境準備

今回はRDBとして`SQLite`を利用します。SQLiteは以下の特徴があります:

- ファイルをDB dataとして扱える
- 軽量で手元で簡単にできる
- そこまで大きくないデータであれば十分に使える
- 独自関数はあんまりない(逆に入門として扱いやすい)
- でもwindow関数は使える
  - https://www.sqlite.org/windowfunctions.html
- もちろんR/RStudioから利用可能

(ほかは口頭で)

#### SQLiteの準備

- Windowsの場合
    - 適当にググってください
- Macの場合
    - **デフォルトでインストールされています**
- Ubuntuの場合
    - `sudo apt install sqlite` でOK

Terminalを起動して、`sqlite3`を実行して出てきてくれればOK。終了コマンドは `.quit`です。ヘルプは`.help`で表示されます。


## 参考資料

(WIP)


[^wide_long]: ピボット変換(wideとlongの変換)がここには入っていません。これはSQLでのピボット変換コードを見るとわかるのですが、実は｢削除｣｢加工｣｢集約｣｢結合｣を組み合わせて表現できます。また並べ替えについても同様です。

[^matrix]: よく誤解されますが、Rにおいて行列は｢ベクトル｣です。一見data.frameっぽく見えますが、あれはベクトルに指定した次元情報をもたせただけの｢1つのベクトル｣です。なので全ての値で同一のデータ型しか許可しません。列志向も行志向もないです。